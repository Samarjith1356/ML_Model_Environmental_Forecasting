{"cells":[{"cell_type":"markdown","id":"6b1ea931","metadata":{"id":"6b1ea931"},"source":["# 1. Intro & imports"]},{"cell_type":"markdown","id":"f98e7747","metadata":{"id":"f98e7747"},"source":["This section introduces the purpose of this utility file, which is to provide reusable functions for loading, cleaning, analyzing, and preparing datasets for machine learning and data analysis. The necessary imports are included here to support all subsequent functions."]},{"cell_type":"code","execution_count":null,"id":"b2e65057","metadata":{"id":"b2e65057"},"outputs":[],"source":["# Styling variables\n","line_start = '\\033[4m'\n","bold_start = '\\033[1m'\n","style_end   = '\\033[0m'\n","bullet_start = '\\u2022 '\n","trait_start = '- '"]},{"cell_type":"code","execution_count":null,"id":"8e0b23b8","metadata":{"id":"8e0b23b8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","\n","\n","\n","# for visual aesthetics for seaborn\n","sns.set(style=\"whitegrid\")"]},{"cell_type":"code","execution_count":null,"id":"2073a374","metadata":{"collapsed":true,"id":"2073a374","outputId":"1a044ac4-7de9-4f95-fcdd-14ccac0b2b7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: prophet in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (1.1.6)\n","Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from prophet) (1.2.4)\n","Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (1.24.3)\n","Requirement already satisfied: matplotlib>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (3.7.1)\n","Requirement already satisfied: pandas>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (1.5.3)\n","Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from prophet) (0.61)\n","Requirement already satisfied: tqdm>=4.36.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (4.65.0)\n","Requirement already satisfied: importlib-resources in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from prophet) (6.4.5)\n","Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n","Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.0.5)\n","Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n","Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2022.7)\n","Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n","Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: keras in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (3.6.0)\n","Requirement already satisfied: tensorflow in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n","Requirement already satisfied: absl-py in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (2.1.0)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.24.3)\n","Requirement already satisfied: rich in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (3.12.1)\n","Requirement already satisfied: optree in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.13.1)\n","Requirement already satisfied: ml-dtypes in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (23.0)\n","Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.29.0)\n","Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (67.8.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n","Collecting numpy (from keras)\n","  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n","                                              0.0/15.9 MB ? eta -:--:--\n","     -                                        0.6/15.9 MB 12.4 MB/s eta 0:00:02\n","     -----                                    2.1/15.9 MB 22.5 MB/s eta 0:00:01\n","     -----------                              4.5/15.9 MB 32.3 MB/s eta 0:00:01\n","     ------------------                       7.4/15.9 MB 39.5 MB/s eta 0:00:01\n","     ------------------------------          12.4/15.9 MB 72.6 MB/s eta 0:00:01\n","     --------------------------------------  15.9/15.9 MB 93.9 MB/s eta 0:00:01\n","     --------------------------------------- 15.9/15.9 MB 65.6 MB/s eta 0:00:00\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n","Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.5.7)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n","Installing collected packages: numpy\n","Successfully installed numpy-2.0.2\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\24339571\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n","tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n","tables 3.8.0 requires cython>=0.29.21, which is not installed.\n","transformers 2.1.1 requires sentencepiece, which is not installed.\n","numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 2.0.2 which is incompatible.\n","scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.0.2 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: keras-tcn in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (3.5.0)\n","Requirement already satisfied: numpy in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras-tcn) (2.0.2)\n","Requirement already satisfied: tensorflow in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras-tcn) (2.18.0)\n","Requirement already satisfied: tensorflow-addons in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras-tcn) (0.22.0)\n","Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->keras-tcn) (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (3.4.0)\n","Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (23.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (5.28.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.29.0)\n","Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (67.8.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (4.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (1.68.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (3.6.0)\n","Requirement already satisfied: h5py>=3.11.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (3.12.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.31.0)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.38.4)\n","Requirement already satisfied: rich in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (13.9.4)\n","Requirement already satisfied: namex in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.0.8)\n","Requirement already satisfied: optree in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2023.5.7)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\24339571\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.2.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.1.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (2.15.1)\n","Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->keras-tcn) (0.1.0)\n"]}],"source":["# Install Prophet\n","!pip install prophet\n","\n","# Install Keras and TensorFlow (for LSTM, Transformer, and TCN)\n","!pip install keras tensorflow\n","\n","# Install TCN package\n","!pip install keras-tcn"]},{"cell_type":"code","execution_count":null,"id":"4604983e","metadata":{"id":"4604983e"},"outputs":[],"source":["# Model Implementaiton\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from tcn import TCN\n","from keras.models import Sequential\n","from sklearn.svm import SVR\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from keras.models import Sequential\n","from keras.layers import Dense, Input, MultiHeadAttention, Dropout, LayerNormalization"]},{"cell_type":"markdown","id":"24bb48fc","metadata":{"id":"24bb48fc"},"source":["# 2.  Data Loading and Basic Information"]},{"cell_type":"markdown","id":"3acbbf54","metadata":{"id":"3acbbf54"},"source":["To load data efficiently and conduct a preliminary inspection, providing insights into the dataset's structure and size."]},{"cell_type":"code","execution_count":null,"id":"d74a0847","metadata":{"id":"d74a0847"},"outputs":[],"source":["def load_data(file_path, max_rows, encoding, dtype):\n","    \"\"\"\n","    Loads a subset of a large CSV file, limited by the specified number of rows.\n","\n","    Parameters:\n","    - file_path (str): Path to the CSV file.\n","    - max_rows (int): Maximum number of rows to load. Default is 500,000.\n","    - encoding (str): File encoding to use. Default is 'ISO-8859-1'.\n","    - dtype (dict): Column data types for memory efficiency.\n","    - low_memory : Ensures consistent data types across all rows by reading the entire file in a single pass\n","\n","    Returns:\n","    - DataFrame: A DataFrame containing the subset of data.\n","    \"\"\"\n","    return pd.read_csv(file_path, nrows=max_rows, encoding=encoding, dtype=dtype, low_memory = False)"]},{"cell_type":"code","execution_count":null,"id":"3f320756","metadata":{"id":"3f320756"},"outputs":[],"source":["def check(data,glance_size):\n","    data_check = data.head(glance_size)\n","    return data_check"]},{"cell_type":"code","execution_count":null,"id":"0dcc5f40","metadata":{"id":"0dcc5f40"},"outputs":[],"source":["def size(data):\n","    data_size = data.shape\n","    return data_size"]},{"cell_type":"markdown","id":"e086bcd5","metadata":{"id":"e086bcd5"},"source":["# 3. Exploratory Data Analysis"]},{"cell_type":"code","execution_count":null,"id":"d955bb08","metadata":{"id":"d955bb08"},"outputs":[],"source":["def initial_eda(data, datetime_column=None):\n","    \"\"\"\n","    Performs essential exploratory data analysis for project-focused insights.\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame to analyze.\n","    - datetime_column (str, optional): The name of the datetime column, if available, for date analysis.\n","\n","    Returns:\n","    - None (prints results for each EDA step).\n","    \"\"\"\n","\n","    # 1. Basic Data Overview\n","    print(\"----- Data Overview -----\")\n","    print(\"Dataset Shape:\", data.shape)\n","    print(\"Column Names:\", list(data.columns))\n","    print(\"Data Types:\\n\", data.dtypes)\n","    print(\"\\nPreview of Data:\\n\", data.head(), \"\\n\")\n","\n","        # Unique Values Analysis\n","    print(\"----- Unique Values Analysis -----\")\n","    unique_values = data.nunique()\n","    print(unique_values.sort_values(ascending=True), \"\\n\")\n","\n","    # 2. Missing Values Summary\n","    print(\"----- Missing Values Summary -----\")\n","    missing_data = data.isnull().mean() * 100  # Percentage of missing values\n","    print(missing_data[missing_data > 0].sort_values(ascending=False), \"\\n\")\n","\n","    # 3. Basic Statistics for Numerical Columns\n","    print(\"----- Basic Statistics (Numerical Columns) -----\")\n","    print(data.describe().T[['mean', 'std', 'min', 'max']], \"\\n\")  # Focused stats\n","\n","    # 4. Date-Time Analysis (if datetime column is provided)\n","    if datetime_column and datetime_column in data.columns:\n","        print(\"----- Date-Time Analysis -----\")\n","        data[datetime_column] = pd.to_datetime(data[datetime_column], errors='coerce')  # Ensure datetime format\n","        print(f\"Date Range for '{datetime_column}':\")\n","        print(\"Min Date:\", data[datetime_column].min())\n","        print(\"Max Date:\", data[datetime_column].max(), \"\\n\")"]},{"cell_type":"code","execution_count":null,"id":"432e4a1f","metadata":{"id":"432e4a1f"},"outputs":[],"source":["def missing_summ(data):\n","    missing_summary = data.isnull().sum()\n","    filtered_summary = missing_summary[missing_summary > 0]\n","    print(filtered_summary)  # Print for visualization\n","    return filtered_summary  # Return the summary"]},{"cell_type":"code","execution_count":null,"id":"43ea4480","metadata":{"id":"43ea4480"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_numeric_histograms(data):\n","    \"\"\"\n","    Plots histograms for all numerical columns in the dataset.\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame containing the data to plot.\n","    \"\"\"\n","    # Select only numerical columns\n","    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n","\n","    # Define the plot layout based on the number of numeric columns\n","    num_cols = len(numeric_columns)\n","    num_rows = (num_cols // 3) + (num_cols % 3 > 0)  # 3 plots per row\n","\n","    # Set up the figure size based on the number of subplots needed\n","    plt.figure(figsize=(15, num_rows * 4))\n","\n","    for i, column in enumerate(numeric_columns, 1):\n","        plt.subplot(num_rows, 3, i)\n","        plt.hist(data[column].dropna(), bins=30, edgecolor='black')\n","        plt.title(column)\n","        plt.xlabel('Value')\n","        plt.ylabel('Frequency')\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"448b5772","metadata":{"id":"448b5772"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_entry_counts(data, date_column, period='M'):\n","    \"\"\"\n","    Plots the number of entries per specified period (e.g., month) to visualize data density over time.\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame containing the data.\n","    - date_column (str): The name of the date column.\n","    - period (str): The period to group by (e.g., 'M' for month, 'Y' for year).\n","\n","    Returns:\n","    - None (displays a plot).\n","    \"\"\"\n","    # Ensure the date column is in datetime format\n","    data[date_column] = pd.to_datetime(data[date_column], errors='coerce')\n","\n","    # Group by the specified period and count entries\n","    entry_counts = data[date_column].dt.to_period(period).value_counts().sort_index()\n","\n","    # Plot the counts\n","    plt.figure(figsize=(12, 6))\n","    entry_counts.plot(kind='bar')\n","    plt.title(f\"Entry Counts per {period} Period\")\n","    plt.xlabel(f\"{period} Period\")\n","    plt.ylabel(\"Number of Entries\")\n","    n = 6  # Display every 6th label\n","    plt.xticks(ticks=range(0, len(entry_counts), n), labels=entry_counts.index[::n], rotation=45)\n","    plt.show()"]},{"cell_type":"markdown","id":"83deea2a","metadata":{"id":"83deea2a"},"source":["# 4. Data Cleaning and Missing Value Handling"]},{"cell_type":"code","execution_count":null,"id":"395fa72c","metadata":{"id":"395fa72c"},"outputs":[],"source":["def fill_missing_values(data, columns, method='interpolate', fill_remaining='forward'):\n","    \"\"\"\n","    Fills missing values in specified numeric columns using the chosen method, with an optional secondary method\n","    for remaining missing values after interpolation.\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame containing the data.\n","    - columns (list): List of columns to fill missing values in.\n","    - method (str): Method to fill missing values. Options: 'mean', 'interpolate'.\n","    - fill_remaining (str): Secondary method to fill remaining missing values. Options: 'forward', 'backward', 'mean'.\n","\n","    Returns:\n","    - DataFrame: Updated DataFrame with filled missing values in specified columns.\n","    \"\"\"\n","    for col in columns:\n","        if method == 'mean':\n","            data[col].fillna(data[col].mean(), inplace=True)\n","        elif method == 'interpolate':\n","            # Perform linear interpolation\n","            data[col].interpolate(method='linear', inplace=True, limit_direction='both')\n","\n","        # Handle any remaining NaNs after interpolation\n","        if fill_remaining == 'forward':\n","            data[col].fillna(method='ffill', inplace=True)\n","        elif fill_remaining == 'backward':\n","            data[col].fillna(method='bfill', inplace=True)\n","        elif fill_remaining == 'mean':\n","            data[col].fillna(data[col].mean(), inplace=True)\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"00814e70","metadata":{"id":"00814e70"},"outputs":[],"source":["# Drops columns with missing values above a specified threshold percentage.\n","def drop_missing_threshold(data, threshold):\n","    # Calculate missing percentage for each column\n","    missing_percentage = data.isnull().mean() * 100\n","    # Identify columns to drop\n","    columns_to_drop = missing_percentage[missing_percentage > threshold].index\n","    # Drop columns\n","    data = data.drop(columns=columns_to_drop, inplace = True)\n","    print(f\"Dropped columns with >{threshold}% missing values: {list(columns_to_drop)}\")\n","    return"]},{"cell_type":"code","execution_count":null,"id":"d8fcbba0","metadata":{"id":"d8fcbba0"},"outputs":[],"source":["def drop_columns(data, columns_to_drop):\n","    # Drop specified columns in place\n","    data.drop(columns=columns_to_drop, inplace=True)\n","    print(f\"Dropped columns: {columns_to_drop}\")"]},{"cell_type":"code","execution_count":null,"id":"1d05232c","metadata":{"id":"1d05232c"},"outputs":[],"source":["# Fill missing 'type' values with the most frequent category\n","def categorical_filling(data, column):\n","    # Find the most frequent value (mode) in the specified column\n","    most_frequent_type = data[column].mode()[0]  # Use the first mode if there are multiple\n","    # Fill missing values with the most frequent value\n","    data[column].fillna(most_frequent_type, inplace=True)\n","\n","    # Check remaining missing values in the DataFrame (optional)\n","    missing_summary = data.isnull().sum()\n","    print(\"Remaining missing values:\\n\", missing_summary[missing_summary > 0])\n","\n","    return data\n"]},{"cell_type":"markdown","id":"12a238f8","metadata":{"id":"12a238f8"},"source":["# 5.Feature Engineering"]},{"cell_type":"code","execution_count":null,"id":"ad7e5405","metadata":{"id":"ad7e5405"},"outputs":[],"source":["collinear_pairs = [\n","    ('height', 'station_pressure_hourly_mB'),  # Drop 'height' and keep 'station_pressure_hourly_mB'\n","    ('wind_speed_hourly_m_s', 'wind_gust_max_m_s')  # Drop 'wind_speed_hourly_m_s' and keep 'wind_gust_max_m_s'\n","]\n","def drop_collinear_features(data, collinear_pairs):\n","\n","    features_to_drop = [pair[0] for pair in collinear_pairs]\n","    print(f\"Dropping collinear features: {features_to_drop}\")\n","    return data.drop(columns=features_to_drop)"]},{"cell_type":"code","execution_count":null,"id":"3d4cf11e","metadata":{"id":"3d4cf11e"},"outputs":[],"source":["def drop_weakly_correlated_features(data, target_variable, threshold=0.2):\n","    \"\"\"\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame containing the features.\n","    - target_variable (str): The name of the target variable.\n","    - threshold (float): The minimum absolute correlation required to keep a feature.\n","\n","    Returns:\n","    - DataFrame: The DataFrame with weakly correlated features dropped.\n","    \"\"\"\n","    correlation_matrix = data.corr()\n","    weak_corr_features = [\n","        col for col in correlation_matrix.columns\n","        if abs(correlation_matrix[col][target_variable]) < threshold and col != target_variable\n","    ]\n","    print(f\"Dropping weakly correlated features: {weak_corr_features}\")\n","    return data.drop(columns=weak_corr_features)\n"]},{"cell_type":"code","execution_count":null,"id":"5267bb0a","metadata":{"id":"5267bb0a"},"outputs":[],"source":["def standardize_date_index_MonthHour(data, date_column):\n","    # If the datetime column is already the index, reset it first to make it a regular column\n","    if data.index.name == date_column:\n","        data = data.reset_index()\n","\n","    # Convert the date column to datetime format\n","    data[date_column] = pd.to_datetime(data[date_column], errors='coerce')\n","\n","    # Drop rows with unparseable dates\n","    data = data.dropna(subset=[date_column])\n","\n","    # Extract the month as a numerical value\n","    data['month'] = data[date_column].dt.month\n","\n","    # Define numeric seasons\n","    def get_season(month):\n","        if month in [12, 1, 2]:\n","            return 1  # Winter\n","        elif month in [3, 4, 5]:\n","            return 2  # Spring\n","        elif month in [6, 7, 8]:\n","            return 3  # Summer\n","        else:\n","            return 4  # Autumn\n","\n","    # Apply the season function to create a numeric 'season' column\n","    data['season'] = data['month'].apply(get_season)\n","\n","    # Define a function to classify hours into time-of-day categories with numeric labels\n","    def classify_time_of_day(hour):\n","        if 5 <= hour < 9:\n","            return 1  # Early Morning\n","        elif 9 <= hour < 12:\n","            return 2  # Morning\n","        elif 12 <= hour < 16:\n","            return 3  # Afternoon\n","        elif 16 <= hour < 20:\n","            return 4  # Evening\n","        else:\n","            return 5  # Night\n","\n","    # Apply the function to create the 'time_of_day' column as a numeric category\n","    data['time_of_day'] = data[date_column].dt.hour.apply(classify_time_of_day)\n","\n","    # Set the exact datetime as the index\n","    data.set_index(date_column, inplace=True)\n","    return data"]},{"cell_type":"markdown","id":"5d6596a8","metadata":{"id":"5d6596a8"},"source":["# 6. Outlier Detection and Handling\n"]},{"cell_type":"code","execution_count":null,"id":"fd5b2c6a","metadata":{"id":"fd5b2c6a"},"outputs":[],"source":["def plot_boxplots(data, numerical_columns):\n","    \"\"\"\n","    Plots boxplots for each numerical column to visualize outliers.\n","    \"\"\"\n","    for col in numerical_columns:\n","        plt.figure(figsize=(8, 4))\n","        sns.boxplot(x=data[col])\n","        plt.title(f'Boxplot of {col}')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0fa6f2d1","metadata":{"id":"0fa6f2d1"},"outputs":[],"source":["from sklearn.preprocessing import RobustScaler\n","def handle_outliers(data, columns, method='cap'):\n","    \"\"\"\n","    Detects and handles outliers in the specified columns using the IQR method with an option to cap or robust scale.\n","\n","    Parameters:\n","    - data (DataFrame): The DataFrame containing the data.\n","    - columns (list): List of columns to check for outliers.\n","    - method (str): Method to handle outliers. Options: 'cap' or 'robust_scale'.\n","\n","    Returns:\n","    - DataFrame: DataFrame with handled outliers.\n","    \"\"\"\n","    data = data.copy()\n","\n","    if method == 'cap':\n","        for col in columns:\n","            Q1 = data[col].quantile(0.25)\n","            Q3 = data[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower_bound = Q1 - 1.5 * IQR\n","            upper_bound = Q3 + 1.5 * IQR\n","            # Cap outliers in the column\n","            data[col] = data[col].clip(lower=lower_bound, upper=upper_bound)\n","\n","    elif method == 'robust_scale':\n","        # Apply RobustScaler to selected columns\n","        scaler = RobustScaler()\n","        data[columns] = scaler.fit_transform(data[columns])\n","\n","    else:\n","        raise ValueError(\"Method not recognized. Use 'cap' or 'robust_scale'.\")\n","\n","    return data"]},{"cell_type":"markdown","id":"85548e04","metadata":{"id":"85548e04"},"source":["## Data Splitting\n"]},{"cell_type":"code","execution_count":null,"id":"a23405a3","metadata":{"id":"a23405a3"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","def split_data(dataset, target_column, test_size=0.2, random_state=42, shuffle=False):\n","    \"\"\"\n","    Splits a dataset into training and testing sets.\n","\n","    Parameters:\n","    - dataset (DataFrame): The full dataset to split.\n","    - target_column (str): The name of the target column.\n","    - test_size (float): The proportion of the dataset to include in the test split.\n","    - random_state (int): Seed used by the random number generator.\n","    - shuffle (bool): Whether to shuffle the data before splitting. Default is False for time-series.\n","\n","    Returns:\n","    - X_train, X_test, y_train, y_test: Split features and target sets.\n","    \"\"\"\n","    X = dataset.drop(columns=[target_column])\n","    y = dataset[target_column]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle\n","    )\n","\n","    print(f\"Data split completed. Training shape: {X_train.shape}, Testing shape: {X_test.shape}\")\n","    return X_train, X_test, y_train, y_test\n"]},{"cell_type":"markdown","id":"451ca3d4","metadata":{"id":"451ca3d4"},"source":["# Model Implementation"]},{"cell_type":"markdown","id":"28908818","metadata":{"id":"28908818"},"source":["### SVR"]},{"cell_type":"code","execution_count":null,"id":"605d07c5","metadata":{"id":"605d07c5"},"outputs":[],"source":["from sklearn.svm import SVR\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","\n","def implement_svr(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'):\n","    \"\"\"\n","    Implements an SVR model for time-series regression.\n","\n","    Parameters:\n","    - kernel (str): Kernel type (e.g., 'rbf', 'linear'). Default is 'rbf'.\n","    - C (float): Regularization parameter. Default is 1.0.\n","    - epsilon (float): Epsilon in the epsilon-SVR model. Default is 0.1.\n","    - gamma (str): Kernel coefficient for 'rbf'. Default is 'scale'.\n","\n","    Returns:\n","    - model: Configured SVR model.\n","    \"\"\"\n","    model = make_pipeline(StandardScaler(), SVR(kernel=kernel, C=C, epsilon=epsilon, gamma=gamma))\n","    return model\n"]},{"cell_type":"markdown","id":"500bae98","metadata":{"id":"500bae98"},"source":["### Transformer Model"]},{"cell_type":"code","execution_count":null,"id":"ef39dc7a","metadata":{"id":"ef39dc7a"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Input, MultiHeadAttention, Dropout, LayerNormalization\n","\n","def implement_transformer(input_dim, num_heads=4, ff_dim=128, dropout_rate=0.1, epochs=20, batch_size=32):\n","    \"\"\"\n","    Implements a Transformer-based model for time-series forecasting.\n","\n","    Parameters:\n","    - input_dim (int): Dimension of the input features.\n","    - num_heads (int): Number of attention heads. Default is 4.\n","    - ff_dim (int): Dimensionality of the feed-forward layer. Default is 128.\n","    - dropout_rate (float): Dropout rate. Default is 0.1.\n","    - epochs (int): Number of training epochs. Default is 20.\n","    - batch_size (int): Batch size for training. Default is 32.\n","\n","    Returns:\n","    - model: Trained Transformer model.\n","    \"\"\"\n","    model = Sequential()\n","    model.add(Input(shape=(None, input_dim)))\n","    model.add(MultiHeadAttention(num_heads=num_heads, key_dim=input_dim))\n","    model.add(Dropout(dropout_rate))\n","    model.add(LayerNormalization())\n","    model.add(Dense(ff_dim, activation='relu'))\n","    model.add(Dense(1))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n"]},{"cell_type":"markdown","id":"ffdf91af","metadata":{"id":"ffdf91af"},"source":["### TCN"]},{"cell_type":"code","execution_count":null,"id":"f7b06475","metadata":{"id":"f7b06475"},"outputs":[],"source":["from tcn import TCN\n","from keras.models import Sequential\n","\n","def implement_tcn(data, lookback=1, filters=64, kernel_size=3, epochs=20, batch_size=32, optimizer='adam', loss='mse'):\n","    \"\"\"\n","    Implements a Temporal Convolutional Network (TCN) model for time-series forecasting.\n","\n","    Parameters:\n","    - data (array-like): Input time-series data.\n","    - lookback (int): Number of previous timesteps to consider. Default is 1.\n","    - filters (int): Number of convolutional filters. Default is 64.\n","    - kernel_size (int): Kernel size for convolution. Default is 3.\n","    - epochs (int): Number of training epochs. Default is 20.\n","    - batch_size (int): Batch size for training. Default is 32.\n","    - optimizer (str): Optimizer to use (e.g., 'adam'). Default is 'adam'.\n","    - loss (str): Loss function to use (e.g., 'mse'). Default is 'mse'.\n","\n","    Returns:\n","    - model: Trained TCN model.\n","    \"\"\"\n","    scaler = MinMaxScaler()\n","    data_scaled = scaler.fit_transform(data.reshape(-1, 1))\n","    X, y = [], []\n","    for i in range(lookback, len(data_scaled)):\n","        X.append(data_scaled[i-lookback:i, 0])\n","        y.append(data_scaled[i, 0])\n","    X, y = np.array(X), np.array(y)\n","    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n","\n","    model = Sequential()\n","    model.add(TCN(input_shape=(X.shape[1], 1), filters=filters, kernel_size=kernel_size))\n","    model.add(Dense(1))\n","    model.compile(optimizer=optimizer, loss=loss)\n","    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)\n","    return model\n"]},{"cell_type":"markdown","id":"fd2b7d57","metadata":{"id":"fd2b7d57"},"source":["### LSTM Model"]},{"cell_type":"code","execution_count":null,"id":"fca1e713","metadata":{"id":"fca1e713"},"outputs":[],"source":["\n","\n","def implement_lstm(data, lookback=1, units=50, epochs=20, batch_size=32, optimizer='adam', loss='mse'):\n","    \"\"\"\n","    Implements an LSTM model for time-series forecasting.\n","\n","    Parameters:\n","    - data (array-like): Input time-series data.\n","    - lookback (int): Number of previous timesteps to consider. Default is 1.\n","    - units (int): Number of LSTM units. Default is 50.\n","    - epochs (int): Number of training epochs. Default is 20.\n","    - batch_size (int): Batch size for training. Default is 32.\n","    - optimizer (str): Optimizer to use (e.g., 'adam'). Default is 'adam'.\n","    - loss (str): Loss function to use (e.g., 'mse'). Default is 'mse'.\n","\n","    Returns:\n","    - model: Trained LSTM model.\n","    \"\"\"\n","    scaler = MinMaxScaler()\n","    data_scaled = scaler.fit_transform(data.reshape(-1, 1))\n","    X, y = [], []\n","    for i in range(lookback, len(data_scaled)):\n","        X.append(data_scaled[i-lookback:i, 0])\n","        y.append(data_scaled[i, 0])\n","    X, y = np.array(X), np.array(y)\n","    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n","\n","    model = Sequential()\n","    model.add(LSTM(units=units, input_shape=(X.shape[1], 1)))\n","    model.add(Dense(1))\n","    model.compile(optimizer=optimizer, loss=loss)\n","    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)\n","    return model\n"]},{"cell_type":"markdown","id":"4bf58a25","metadata":{"id":"4bf58a25"},"source":["### Prophet"]},{"cell_type":"code","execution_count":null,"id":"4YJ9qjJP8nn9","metadata":{"id":"4YJ9qjJP8nn9"},"outputs":[],"source":["# Reshape data for Prophet\n","def reshape_for_prophet(data, date_col, target_col):\n","    \"\"\"\n","    Reshape the data for Prophet model implementation.\n","\n","    Parameters:\n","    - data (DataFrame): Input dataset.\n","    - date_col (str): Column name for the date.\n","    - target_col (str): Column name for the target variable.\n","\n","    Returns:\n","    - DataFrame: Reshaped dataset with columns 'ds' and 'y'.\n","    \"\"\"\n","    prophet_data = data[[date_col, target_col]].rename(columns={date_col: 'ds', target_col: 'y'})\n","    return prophet_data\n"]},{"cell_type":"code","execution_count":null,"id":"658a79e4","metadata":{"id":"658a79e4"},"outputs":[],"source":["def implement_prophet(train_data, growth='linear', seasonality_mode='additive', changepoint_prior_scale=0.05):\n","    \"\"\"\n","    Implements the Prophet model on training data.\n","\n","    Parameters:\n","    - train_data (DataFrame): Training dataset with 'ds' (date) and 'y' (target).\n","    - growth (str): Growth trend ('linear' or 'logistic').\n","    - seasonality_mode (str): Seasonality mode ('additive' or 'multiplicative').\n","    - changepoint_prior_scale (float): Regularization strength for changepoints.\n","\n","    Returns:\n","    - model (Prophet object): Fitted Prophet model.\n","    \"\"\"\n","    model = Prophet(growth=growth, seasonality_mode=seasonality_mode, changepoint_prior_scale=changepoint_prior_scale)\n","    model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n","    model.fit(train_data)\n","    return model\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}